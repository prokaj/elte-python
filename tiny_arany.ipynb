{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dm-haiku==0.0.9\n",
      "jax==0.3.25\n",
      "jaxlib==0.3.25\n",
      "tensorflow==2.11.0\n",
      "tensorflow-datasets==4.7.0\n",
      "tensorflow-estimator==2.11.0\n",
      "tensorflow-io-gcs-filesystem==0.27.0\n",
      "tensorflow-metadata==1.11.0\n"
     ]
    }
   ],
   "source": [
    "! pip freeze | grep -e 'optax' -e 'haiku' -e 'jax' -e 'tensorflow'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optax\n",
      "  Downloading optax-0.1.4-py3-none-any.whl (154 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.9/154.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /home/prokaj/.config/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from optax) (1.23.2)\n",
      "Requirement already satisfied: jax>=0.1.55 in /home/prokaj/.config/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from optax) (0.3.25)\n",
      "Requirement already satisfied: jaxlib>=0.1.37 in /home/prokaj/.config/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from optax) (0.3.25)\n",
      "Requirement already satisfied: absl-py>=0.7.1 in /home/prokaj/.config/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from optax) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in /home/prokaj/.config/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from optax) (4.3.0)\n",
      "Collecting chex>=0.1.5\n",
      "  Downloading chex-0.1.5-py3-none-any.whl (85 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: toolz>=0.9.0 in /home/prokaj/.config/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from chex>=0.1.5->optax) (0.12.0)\n",
      "Collecting dm-tree>=0.1.5\n",
      "  Downloading dm_tree-0.1.7-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (142 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.6/142.6 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.5 in /home/prokaj/.config/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from jax>=0.1.55->optax) (1.9.1)\n",
      "Requirement already satisfied: opt-einsum in /home/prokaj/.config/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from jax>=0.1.55->optax) (3.3.0)\n",
      "Installing collected packages: dm-tree, chex, optax\n",
      "Successfully installed chex-0.1.5 dm-tree-0.1.7 optax-0.1.4\n"
     ]
    }
   ],
   "source": [
    "! pip install optax # jax dm-haiku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Karakter RNN Arany János művein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az `arany-osszes.txt` file-t az alábbi módon hozhatjuk létre:\n",
    "```\n",
    "! wget https://mek.oszk.hu/00500/00597/00597.doc\n",
    "! libreoffice --cat 00597.doc > arany-osszes.txt\n",
    "! rm 00597.doc\n",
    "```\n",
    "\n",
    "<small><pre>\n",
    "--2022-12-04 11:35:58--  https://mek.oszk.hu/00500/00597/00597.doc\n",
    "Resolving mek.oszk.hu (mek.oszk.hu)... 193.6.201.253, 2001:738:0:306::2\n",
    "Connecting to mek.oszk.hu (mek.oszk.hu)|193.6.201.253|:443... connected.\n",
    "HTTP request sent, awaiting response... 200 OK\n",
    "Length: 4733440 (4,5M) [application/msword]\n",
    "Saving to: ‘00597.doc’\n",
    "\n",
    "00597.doc           100%[===================>]   4,51M  2,74MB/s    in 1,7s    \n",
    "\n",
    "2022-12-04 11:36:00 (2,74 MB/s) - ‘00597.doc’ saved [4733440/4733440]\n",
    "\n",
    "Warning: failed to launch javaldx - java may not function correctly\n",
    "\n",
    "(soffice:30311): Gtk-WARNING **: 11:36:01.969: Could not load a pixbuf from icon theme.\n",
    "This may indicate that pixbuf loaders or the mime database could not be found.\n",
    "</pre></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colab-on nem érhető el libreoffice. Lehet, hogy lehetne telepíteni, vagy más eszközt használni a szöveg kinyerésére. HF hogyan.\n",
    "\n",
    "A kurzus github oldalára feltöltöttem az elkészült szöveg file-t, azt fogjuk használni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://github.com/prokaj/elte-python/raw/main/arany-osszes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ARANY JÁNOS\n",
      "ÖSSZES KÖLTEMÉNYEI\n",
      "\n",
      "\n",
      "TARTALOM\n",
      "\n",
      "\n",
      "Versek\n",
      "VÁLASZ PETŐFINEK\n",
      "A VARRÓ LEÁNYOK\n",
      "A MÉH ROMÁNCA\n",
      "ARANYAIMHOZ\n",
      "EGYKORI TANÍTVÁNYOM EMLÉKKÖNYVÉBE\n",
      "ARCOM VONÁSIT...\n",
      "ÖLDÖKLŐ ANGYAL\n",
      "CSANÁD\n",
      "RÓZSA ÉS IBOLYA II.\n",
      "KEVEHÁZA\n",
      "CSABA KIRÁLYFI\n",
      "CSABA TRILÓGIA (Első dolgozat)\n",
      "A ZRINYIÁSZ NÉPIES KIDOLGOZÁSA\n",
      "AZ UTOLSÓ MAGYAR\n",
      "BUDA HALÁLA\n",
      "A CSABA-TRILÓGIA ÚJABB ALAPRAJZA\n",
      "CSABA TRILÓGIA  (Utolsó dolgozat)\n",
      "\n",
      "\n",
      "\n",
      "Versek\n",
      "VÁLASZ PETŐFINEK\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('arany-osszes.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "print(''.join(lines[:15]+lines[433-15:434]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VÁLASZ PETŐFINEK\\n'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[433]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54183,\n",
       " 2709.15,\n",
       " ['VÁLASZ PETŐFINEK\\n',\n",
       "  'Zavarva lelkem, mint a bomlott cimbalom;\\n',\n",
       "  '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Örűl a szívem és mégis sajog belé,\\n',\n",
       "  'Hányja veti a hab: mért e nagy jutalom?\\n',\n",
       "  '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Petőfit barátul mégsem érdemelé.\\n',\n",
       "  'Hiszen pályadíjul ez nem volt kitűzve...\\n',\n",
       "  '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Szerencse, isteni jó szerencse nékem!\\n',\n",
       "  'Máskép szerény művem vetém vala tűzbe,\\n',\n",
       "  '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Mert hogyan lett volna nyerni reménységem?\\n',\n",
       "  'És mily sokat nyerék! Pusztán a pályabér\\n'])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not lines[0].startswith('VÁLASZ PETŐFINEK'):\n",
    "    lines = lines[433:]\n",
    "len(lines), 0.05*len(lines), lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2740, 'Szíves, de bánatos üdvözletem.\\n'),\n",
       " (2741, 'Repülj utadra most... de nem, ne még,\\n'),\n",
       " (2742, 'Száritsd föl nedvesült szárnyaidat:\\n'),\n",
       " (2743, 'Nehéz vagy a könnyhullatás miatt,\\n'),\n",
       " (2744, 'Mellyel emlékeinek áldozék.\\n'),\n",
       " (2745, 'Majd csak felszárad a könny... ámde a bú? -\\n'),\n",
       " (2746, 'Oszlik talán egy hosszu életen. -\\n'),\n",
       " (2747, 'Vidd asszonyodnak, egyszerű lapocska,\\n'),\n",
       " (2748, 'Szíves, de bánatos üdvözletem.\\n'),\n",
       " (2749, '(1850)\\n'),\n",
       " (2750, 'FURKÓ TAMÁS\\n'),\n",
       " (2751, 'Ki zengi meg, ha én nem, a mult nagy napjait:\\n'),\n",
       " (2752, 'Vitéz Furkó Tamásnak kegyetlen dolgait,\\n'),\n",
       " (2753, 'Amelyeket viselt... vagy, mondani akarom:\\n'),\n",
       " (2754, 'Mik őt úgy megviselték, vizen és szárazon.\\n'),\n",
       " (2755, 'Mindig bolond hónap volt, mióta e világ,\\n'),\n",
       " (2756, 'Az, melyet márciusnak keresztelt a diák:\\n'),\n",
       " (2757, 'Fagy, hó, eső, derült ég, vihar... mind egy napon!\\n'),\n",
       " (2758, 'Csak úgy bámul belé a bölcs kalendárium.\\n'),\n",
       " (2759, 'De amióta Caesart hatalma nimbusán\\n'),\n",
       " (2760, 'Megdönték a zavargók Martius idusán,\\n'),\n",
       " (2761, 'Nem volt e hónak olyan tizenötödike,\\n'),\n",
       " (2762, 'Mint az, mely harmadéve amúgy közénk üte.\\n'),\n",
       " (2763, 'E volt ütés magáért! ez volt a csattanás!\\n'),\n",
       " (2764, 'Szemét-fülét behúnyta nemes Furkó Tamás: -\\n'),\n",
       " (2765, 'Hiába! mindhiába!... most is zúg a füle,\\n'),\n",
       " (2766, 'S nemzetiszín karikát hány a szeme bele.\\n'),\n",
       " (2767, 'Egyszerre megtagadva ötvenkilenc robot!\\n'),\n",
       " (2768, 'Egyszerre széjjeltörve a mogyorófa bot!\\n'),\n",
       " (2769, 'Egyszerre úr a jobbágy: kalapját fölteszi,\\n')]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineno = 2740\n",
    "list(enumerate(lines[lineno:lineno+30], lineno))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Szíves, de bánatos üdvözletem.\n",
      "Repülj utadra most... de nem, ne még,\n",
      "Száritsd föl nedvesült szárnyaidat:\n",
      "Nehéz vagy a könnyhullatás miatt,\n",
      "Mellyel emlékeinek áldozék.\n",
      "Majd csak felszárad a könny... ámde a bú? -\n",
      "Oszlik talán egy hosszu életen. -\n",
      "Vidd asszonyodnak, egyszerű lapocska,\n",
      "Szíves, de bánatos üdvözletem.\n",
      "(1850)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FURKÓ TAMÁS\n",
      "Ki zengi meg, ha én nem, a mult nagy napjait:\n",
      "Vitéz Furkó Tamásnak kegyetlen dolgait,\n",
      "Amelyeket viselt... vagy, mondani akarom:\n",
      "Mik őt úgy megviselték, vizen és szárazon.\n",
      "Mindig bolond hónap volt, mióta e világ,\n",
      "Az, melyet márciusnak keresztelt a diák:\n",
      "Fagy, hó, eső, derült ég, vihar... mind egy napon!\n",
      "Csak úgy bámul belé a bölcs kalendárium.\n",
      "De amióta Caesart hatalma nimbusán\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_lines = lines[:2750]\n",
    "train_lines = lines[2750:]\n",
    "\n",
    "print(''.join(test_lines[-10:]))\n",
    "print('-'*100)\n",
    "print(''.join(train_lines[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "cnt_char = Counter(chain.from_iterable(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !()*,-.0123456789:;<=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz| «­»ÁÂÉÍÓÖÚÜáäéëíîóôöúüŐőŰű‘’”„\n",
      "Counter({' ': 233976, 'e': 137532, 'a': 122239, 't': 100108, 'n': 88813, 'l': 86906, 's': 77114, 'r': 60215, 'k': 57595, 'o': 56734, 'i': 56391, 'z': 54694, '\\n': 54183, 'g': 51262, 'm': 50227, 'á': 50094, 'é': 43020, ',': 41929, 'y': 39060, 'd': 35166, 'v': 29797, 'b': 26781, 'h': 23873, 'j': 21762, 'ö': 17063, '.': 15713, '\\xa0': 14914, 'u': 13193, 'f': 12964, 'p': 12613, 'ő': 11373, 'ó': 10815, 'c': 10704, 'M': 7812, '-': 7599, 'ü': 7326, ':': 7232, 'S': 5754, 'í': 5701, 'A': 5659, ';': 5513, 'H': 5095, 'ú': 4941, '!': 4363, 'E': 3954, 'K': 3904, 'N': 3619, '„': 3469, 'ű': 3030, 'T': 2753, '”': 2542, 'V': 2435, '?': 2378, 'D': 2361, 'B': 2326, 'I': 2316, 'L': 2178, 'F': 1871, 'É': 1763, '1': 1586, 'R': 1399, 'O': 1394, '’': 1289, 'C': 1263, 'P': 1127, 'J': 1115, ')': 989, '(': 987, 'G': 984, '8': 912, '2': 848, 'Á': 778, '5': 686, '3': 617, '7': 604, '4': 560, '6': 539, 'Ö': 535, 'Z': 493, '9': 433, 'Í': 420, '0': 418, 'U': 399, 'Ú': 363, 'Ő': 333, 'Ó': 184, 'Ü': 158, 'Y': 144, '»': 84, '«': 74, 'X': 43, 'W': 37, 'x': 35, '*': 34, '\\xad': 27, 'w': 25, '|': 25, 'q': 22, '\\uf0c8': 21, 'Ű': 16, '_': 16, '<': 15, 'Q': 11, 'ä': 9, '‘': 5, 'ë': 4, '\\uf06f': 4, '\\uf020': 3, '\\uf061': 3, '\\uf065': 3, 'î': 2, '\\uf06e': 2, '\\uf06d': 2, '\\uf056': 2, '=': 1, 'Â': 1, 'ô': 1, '[': 1, ']': 1, '\\uf054': 1, '\\uf064': 1, '\\uf070': 1, '\\uf069': 1, '\\uf062': 1, '\\uf041': 1, '\\uf075': 1, '\\uf074': 1, '\\uf066': 1, '\\uf02b': 1, '\\uf0d6': 1, '\\uf0a5': 1})\n"
     ]
    }
   ],
   "source": [
    "print(''.join(sorted(cnt_char.keys())))\n",
    "print(cnt_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\\xad` a soft-hyphen karakter, `xa0` non-breakable space, `\\uf0..` csak egy helyen használatos a hexaméterek ritmusának leírására. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V', 'Á', 'L', 'A', 'S', 'Z', ' ', 'P', 'E', 'T', 'Ő', 'F', 'I', 'N', 'K', '\\n', 'a', 'v', 'r', 'l', 'e', 'k', 'm', ',', 'i', 'n', 't', 'b', 'o', 'c', ';', 'Ö', 'ű', 's', 'z', 'í', 'é', 'g', 'j', 'H', 'á', 'y', 'h', ':', 'u', '?', 'ő', 'f', 'd', '.', 'p', 'ó', '!', 'M', 'É', 'D', 'ö', 'O', '-', 'J', 'ú', 'ü', '(', '1', '8', '4', '7', ')', 'R', 'Ó', 'Y', 'B', 'G', 'C', '’', 'U', '„', '”', 'Ü', 'Í', '2', 'Ú', '3', 'w', 'x', 'X', '6', '5', '9', '*', '0', '=', 'Q', 'ë', '‘', 'Ű', 'ä', 'W', 'î', 'q', 'Â', 'ô', '»', '«', '|', '<', '[', ']', '_']\n"
     ]
    }
   ],
   "source": [
    "letters = [k for k in cnt_char if ord(k)< int('f000', 16) and k not in '\\xa0\\xad']\n",
    "print(letters)\n",
    "int2char = dict(enumerate(letters, 1))\n",
    "char2int = {k: i for i, k in int2char.items()}\n",
    "char2int['\\xa0'] = char2int[' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2int_array(txt):\n",
    "    result = []\n",
    "    for x in txt:\n",
    "        code = char2int.get(x, -1)\n",
    "        if code>-1:\n",
    "            result.append(code)\n",
    "    return np.array(result, dtype=np.int32)\n",
    "\n",
    "def int_array2str(arr: np.ndarray):\n",
    "    return ''.join(int2char[x] for x in arr)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = text2int_array(chain.from_iterable(train_lines))\n",
    "test_data = text2int_array(chain.from_iterable(test_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VÁLASZ PETŐFINEK\\n', 'Zavarva lelkem, mint a bomlott cimbalom;\\n', '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Örűl a szívem és mégis sajog belé,\\n', 'Hányja veti a hab: mért e nagy jutalom?\\n', '\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Petőfit barátul mégsem érdemelé.\\n']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'VÁLASZ PETŐFINEK\\nZavarva lelkem, mint a bomlott cimbalom;\\n      Örűl a szívem és mégis sajog belé,\\nH'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lines[:5])\n",
    "int_array2str(test_data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.data as tf_data\n",
    "from tensorflow.nest import map_structure as tf_map_structure\n",
    "from tensorflow import transpose as tf_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ds(\n",
    "    lines,\n",
    "    sequence_len=128, \n",
    "    batch_size=32\n",
    "):\n",
    "    encoded_text = text2int_array(chain.from_iterable(lines))\n",
    "\n",
    "    ds = tf_data.Dataset.from_tensors({'text': encoded_text})\n",
    "    ds = ds.map(lambda x: {'input': x['text'][:-1], 'target': x['text'][1:]})\n",
    "    ds = ds.unbatch()\n",
    "    ds = ds.batch(sequence_len, drop_remainder=True)\n",
    "    ds = ds.shuffle(100)\n",
    "    ds = ds.repeat()\n",
    "    ds = ds.batch(batch_size=batch_size)\n",
    "    ds = ds.map(lambda b: tf_map_structure(tf_transpose, b))  # Time major\n",
    "\n",
    "    return ds.as_numpy_iterator()\n",
    "\n",
    "NUM_CHARS = max(int2char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109, 1)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CHARS, min(int2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_ds = make_ds(test_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch = next(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': array([[42, 27, 34, ...,  7, 26, 50],\n",
       "        [28, 25, 35, ..., 38, 27, 50],\n",
       "        [21,  7, 21, ..., 42, 21, 16],\n",
       "        ...,\n",
       "        [26, 36, 20, ..., 21, 20, 19],\n",
       "        [49, 18, 42, ..., 23, 21, 24],\n",
       "        [21, 21, 21, ..., 21, 26, 16]], dtype=int32),\n",
       " 'target': array([[28, 25, 35, ..., 38, 27, 50],\n",
       "        [21,  7, 21, ..., 42, 21, 16],\n",
       "        [26, 21, 19, ..., 21,  7, 63],\n",
       "        ...,\n",
       "        [49, 18, 42, ..., 23, 21, 24],\n",
       "        [21, 21, 21, ..., 21, 26, 16],\n",
       "        [26,  7, 27, ..., 27,  7, 72]], dtype=int32)}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "BYrH9wiwjFnU"
   },
   "outputs": [],
   "source": [
    "# Copyright 2020 DeepMind Technologies Limited. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Character-level language modelling with a recurrent network in JAX.\"\"\"\n",
    "\n",
    "from typing import Any, NamedTuple\n",
    "\n",
    "from absl import logging\n",
    "from absl import flags\n",
    "\n",
    "import haiku as hk\n",
    "\n",
    "import jax\n",
    "from jax import lax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "\n",
    "if not hasattr(flags.FLAGS, 'train_batch_size'):\n",
    "    TRAIN_BATCH_SIZE = flags.DEFINE_integer('train_batch_size', 32, '')\n",
    "    EVAL_BATCH_SIZE = flags.DEFINE_integer('eval_batch_size', 1000, '')\n",
    "    SEQUENCE_LENGTH = flags.DEFINE_integer('sequence_length', 128, '')\n",
    "    HIDDEN_SIZE = flags.DEFINE_integer('hidden_size', 256, '')\n",
    "    SAMPLE_LENGTH = flags.DEFINE_integer('sample_length', 128, '')\n",
    "    LEARNING_RATE = flags.DEFINE_float('learning_rate', 1e-3, '')\n",
    "    TRAINING_STEPS = flags.DEFINE_integer('training_steps', 50_000, '')\n",
    "    EVALUATION_INTERVAL = flags.DEFINE_integer('evaluation_interval', 1000, '')\n",
    "    SAMPLING_INTERVAL = flags.DEFINE_integer('sampling_interval', 1000, '')\n",
    "    SEED = flags.DEFINE_integer('seed', 42, '')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "FE1312fhkbID"
   },
   "outputs": [],
   "source": [
    "from absl import app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4sOxSnnjjjNN",
    "outputId": "913f23a7-1e40-4fbb-ca34-b227224cac0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.parse_flags_with_usage(['main', '-v', '1'])\n",
    "#flags.ArgumentParser().parse('')\n",
    "TRAIN_BATCH_SIZE.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ebdv9EXsjsq1",
    "outputId": "c2e220b3-324a-4410-95a6-8a41d1292c1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logtostderr': False,\n",
       " 'alsologtostderr': False,\n",
       " 'log_dir': '',\n",
       " 'v': 1,\n",
       " 'verbosity': 1,\n",
       " 'logger_levels': {},\n",
       " 'stderrthreshold': 'fatal',\n",
       " 'showprefixforinfo': True,\n",
       " 'run_with_pdb': False,\n",
       " 'pdb_post_mortem': False,\n",
       " 'pdb': False,\n",
       " 'run_with_profiling': False,\n",
       " 'profile_file': None,\n",
       " 'use_cprofile_for_profiling': True,\n",
       " 'only_check_args': False,\n",
       " 'op_conversion_fallback_to_while_loop': True,\n",
       " 'runtime_oom_exit': True,\n",
       " 'hbm_oom_exit': True,\n",
       " 'delta_threshold': 0.5,\n",
       " 'tt_check_filter': False,\n",
       " 'tt_single_core_summaries': False,\n",
       " 'test_srcdir': '',\n",
       " 'test_tmpdir': '/tmp/absl_testing',\n",
       " 'test_random_seed': 301,\n",
       " 'test_randomize_ordering_seed': '',\n",
       " 'xml_output_file': '',\n",
       " 'chex_n_cpu_devices': 1,\n",
       " 'chex_assert_multiple_cpu_devices': False,\n",
       " 'chex_skip_pmap_variant_if_single_device': True,\n",
       " 'train_batch_size': 32,\n",
       " 'eval_batch_size': 1000,\n",
       " 'sequence_length': 128,\n",
       " 'hidden_size': 256,\n",
       " 'sample_length': 128,\n",
       " 'learning_rate': 0.001,\n",
       " 'training_steps': 50000,\n",
       " 'evaluation_interval': 1000,\n",
       " 'sampling_interval': 1000,\n",
       " 'seed': 42}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flags.FLAGS.flag_values_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDDSUWldYEA8"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class LoopValues(NamedTuple):\n",
    "  tokens: jnp.ndarray\n",
    "  state: Any\n",
    "  rng_key: jnp.ndarray\n",
    "\n",
    "\n",
    "class TrainingState(NamedTuple):\n",
    "  params: hk.Params\n",
    "  opt_state: optax.OptState\n",
    "\n",
    "\n",
    "def make_network() -> hk.RNNCore:\n",
    "  \"\"\"Defines the network architecture.\"\"\"\n",
    "  model = hk.DeepRNN([\n",
    "      lambda x: jax.nn.one_hot(x, num_classes=NUM_CHARS),\n",
    "      hk.LSTM(HIDDEN_SIZE.value),\n",
    "      jax.nn.relu,\n",
    "      hk.LSTM(HIDDEN_SIZE.value),\n",
    "      hk.nets.MLP([HIDDEN_SIZE.value, NUM_CHARS]),\n",
    "  ])\n",
    "  return model\n",
    "\n",
    "\n",
    "def make_optimizer() -> optax.GradientTransformation:\n",
    "  \"\"\"Defines the optimizer.\"\"\"\n",
    "  return optax.adam(LEARNING_RATE.value)\n",
    "\n",
    "\n",
    "def sequence_loss(batch: Batch) -> jnp.ndarray:\n",
    "  \"\"\"Unrolls the network over a sequence of inputs & targets, gets loss.\"\"\"\n",
    "  # Note: this function is impure; we hk.transform() it below.\n",
    "  core = make_network()\n",
    "  sequence_length, batch_size = batch['input'].shape\n",
    "  initial_state = core.initial_state(batch_size)\n",
    "  logits, _ = hk.dynamic_unroll(core, batch['input'], initial_state)\n",
    "  log_probs = jax.nn.log_softmax(logits)\n",
    "  one_hot_labels = jax.nn.one_hot(batch['target'], num_classes=logits.shape[-1])\n",
    "  return -jnp.sum(one_hot_labels * log_probs) / (sequence_length * batch_size)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def update(state: TrainingState, batch: Batch) -> TrainingState:\n",
    "  \"\"\"Does a step of SGD given inputs & targets.\"\"\"\n",
    "  _, optimizer = make_optimizer()\n",
    "  _, loss_fn = hk.without_apply_rng(hk.transform(sequence_loss))\n",
    "  gradients = jax.grad(loss_fn)(state.params, batch)\n",
    "  updates, new_opt_state = optimizer(gradients, state.opt_state)\n",
    "  new_params = optax.apply_updates(state.params, updates)\n",
    "  return TrainingState(params=new_params, opt_state=new_opt_state)\n",
    "\n",
    "\n",
    "def sample(\n",
    "    rng_key: jnp.ndarray,\n",
    "    context: jnp.ndarray,\n",
    "    sample_length: int,\n",
    ") -> jnp.ndarray:\n",
    "  \"\"\"Draws samples from the model, given an initial context.\"\"\"\n",
    "  # Note: this function is impure; we hk.transform() it below.\n",
    "  assert context.ndim == 1  # No batching for now.\n",
    "  core = make_network()\n",
    "\n",
    "  def body_fn(t: int, v: LoopValues) -> LoopValues:\n",
    "    token = v.tokens[t]\n",
    "    next_logits, next_state = core(token, v.state)\n",
    "    key, subkey = jax.random.split(v.rng_key)\n",
    "    next_token = jax.random.categorical(subkey, next_logits, axis=-1)\n",
    "    new_tokens = v.tokens.at[t + 1].set(next_token)\n",
    "    return LoopValues(tokens=new_tokens, state=next_state, rng_key=key)\n",
    "\n",
    "  logits, state = hk.dynamic_unroll(core, context, core.initial_state(None))\n",
    "  key, subkey = jax.random.split(rng_key)\n",
    "  first_token = jax.random.categorical(subkey, logits[-1])\n",
    "  tokens = jnp.zeros(sample_length, dtype=np.int32)\n",
    "  tokens = tokens.at[0].set(first_token)\n",
    "  initial_values = LoopValues(tokens=tokens, state=state, rng_key=key)\n",
    "  values: LoopValues = lax.fori_loop(0, sample_length, body_fn, initial_values)\n",
    "\n",
    "  return values.tokens\n",
    "\n",
    "\n",
    "def main():\n",
    "  flags.FLAGS.alsologtostderr = True\n",
    "  flags.FLAGS.verbosity = 1\n",
    "\n",
    "  # Make training dataset.\n",
    "  train_data = make_ds(\n",
    "      train_lines,\n",
    "      batch_size=TRAIN_BATCH_SIZE.value,\n",
    "      sequence_len=SEQUENCE_LENGTH.value\n",
    "    )\n",
    "\n",
    "  # Make evaluation dataset(s).\n",
    "  eval_data = {  # pylint: disable=g-complex-comprehension\n",
    "      'train': make_ds(\n",
    "        train_lines,\n",
    "        batch_size=EVAL_BATCH_SIZE.value,\n",
    "        sequence_len=SEQUENCE_LENGTH.value\n",
    "      ),\n",
    "      'test': make_ds(\n",
    "        test_lines,\n",
    "        batch_size=EVAL_BATCH_SIZE.value,\n",
    "        sequence_len=SEQUENCE_LENGTH.value\n",
    "      )\n",
    "  }\n",
    "\n",
    "  # Make loss, sampler, and optimizer.\n",
    "  params_init, loss_fn = hk.without_apply_rng(hk.transform(sequence_loss))\n",
    "  _, sample_fn = hk.without_apply_rng(hk.transform(sample))\n",
    "  opt_init, _ = make_optimizer()\n",
    "\n",
    "  loss_fn = jax.jit(loss_fn)\n",
    "  sample_fn = jax.jit(sample_fn, static_argnums=[3])\n",
    "\n",
    "  # Initialize training state.\n",
    "  rng = hk.PRNGSequence(SEED.value)\n",
    "  initial_params = params_init(next(rng), next(train_data))\n",
    "  initial_opt_state = opt_init(initial_params)\n",
    "  state = TrainingState(params=initial_params, opt_state=initial_opt_state)\n",
    "\n",
    "  # Training loop.\n",
    "  for step in range(TRAINING_STEPS.value + 1):\n",
    "    # Do a batch of SGD.\n",
    "    train_batch = next(train_data)\n",
    "    state = update(state, train_batch)\n",
    "\n",
    "    # Periodically generate samples.\n",
    "    if step % SAMPLING_INTERVAL.value == 0:\n",
    "      context = train_batch['input'][:, 0]  # First element of training batch.\n",
    "      assert context.ndim == 1\n",
    "      rng_key = next(rng)\n",
    "      samples = sample_fn(state.params, rng_key, context, SAMPLE_LENGTH.value)\n",
    "\n",
    "      prompt = decode(context)\n",
    "      continuation = decode(samples)\n",
    "\n",
    "      logging.info('\\n===Prompt:\\n%s\\n===\\n', prompt)\n",
    "      logging.info('\\n---Continuation:\\n%s\\n---\\n', continuation)\n",
    "\n",
    "    # Periodically evaluate training and test loss.\n",
    "    if step % EVALUATION_INTERVAL.value == 0:\n",
    "      for split, ds in eval_data.items():\n",
    "        eval_batch = next(ds)\n",
    "        loss = loss_fn(state.params, eval_batch)\n",
    "        logging.info({\n",
    "            'step': step,\n",
    "            'loss': float(loss),\n",
    "            'split': split,\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8b53ac59aeb7dd99955ed1c7af180cec0b2adbd03b0a8162d4077beb5f10154"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
